{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5ccf458e-0495-4f5c-8151-f6b6843269ca",
   "metadata": {},
   "source": [
    "Test models on AWS bedrock using boto3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e7f377c5-fc43-4da7-ae50-5df6e675212a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import boto3\n",
    "import openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7bbf4ca2-2c68-4f00-a3d9-e5ead31fd0c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../config.json\", \"r\") as f:\n",
    "    CONFIG = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63ea6a5f-7eea-404e-88c9-0966f2b90fbf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "client = boto3.client(\n",
    "    'bedrock-runtime', \n",
    "    aws_access_key_id = CONFIG[\"aws_access_key_id\"], \n",
    "    aws_secret_access_key = CONFIG[\"aws_secret_access_key\"],\n",
    "    region_name = \"us-east-1\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff585dbc-e5bd-45a5-958c-ef205093af55",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_prompt = '''\n",
    "SYSTEM: Provide a response for the tutor to the student learning Japanese.\n",
    "Provide only the succeeding response. Do not continue the conversation further.\n",
    "Separate the output into two parts: \n",
    "<feedback> Give feedback on the grammar of the student in his last response.\n",
    "<response> A response to keep the conversation going.\n",
    "Use this json syntax:\n",
    "{\n",
    "\"feedback\": \"<feedback>\",\n",
    "\"response\": \"<response>\"\n",
    "}\n",
    "The student is a native english speaker. Comment on his grammar in English, but write samples in Japanese text.\n",
    "The response should be in Japanese text.\n",
    "\n",
    "STUDENT: 今日、僕は何が勉強しますか？\n",
    "TUTOR:\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bce4c76b-f41e-44d1-bc47-4be1d11ba15c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_id = 'cohere.command-text-v14'\n",
    "accept = '*/*'\n",
    "content_type = 'application/json'\n",
    "\n",
    "\n",
    "# NOTE: these parameters need to be appropriate for the model\n",
    "body = json.dumps({\n",
    "    \"prompt\": sample_prompt,\n",
    "    \"max_tokens\": 500,\n",
    "    \"temperature\": 0.0,\n",
    "})\n",
    "\n",
    "response = client.invoke_model(\n",
    "    modelId = model_id,\n",
    "    body = body,\n",
    "    accept = accept,\n",
    "    contentType = content_type\n",
    ")\n",
    "\n",
    "response_body = json.loads(response.get('body').read())\n",
    "print(response_body['generations'][0]['text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab349e53-7e22-48a9-9d28-f6447a5266b1",
   "metadata": {},
   "source": [
    "Looks like the Cohere model got the syntax right, but the feedback is actually wrong..\n",
    "<br> Could get better with reference doc, but check if other models get this right just from weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f160f3ba-4069-4634-957c-d6d1c13b8d9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "openai.api_key = CONFIG[\"openai_api_key\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1b83360f-9e44-403e-a340-f4b5f536c93a",
   "metadata": {},
   "outputs": [],
   "source": [
    "conversation = [\n",
    "    {\n",
    "        \"role\": \"system\", \n",
    "        \"content\": '''\n",
    "        You are a tutor to a student learning Japanese.\n",
    "        Converse with the student and give feedback on his Japanese.\n",
    "        Your response should contain both feedback for the student and a response to continue the conversation.\n",
    "        Respond using this json syntax:\n",
    "        {\n",
    "            \"feedback\": \"<feedback>\",\n",
    "            \"message\": \"<message>\"\n",
    "        }\n",
    "        In the <feedback> value, provide feedback and suggestions for improving his Japanese.\n",
    "        The student is a native english speaker. \n",
    "        Comment on his grammar in English, but write samples in Japanese text.\n",
    "        \n",
    "        In the <message> value, reply to his query to keep the conversation going.\n",
    "        The message should be in Japanese text.\n",
    "        Make a message that encourages him to continue conversing.\n",
    "\n",
    "        Here is a sample response:\n",
    "        {\n",
    "            \"feedback\": \"\n",
    "            In your previous statement, it is more correct to say '教えてください'　than '教えるください'.\n",
    "            \",\n",
    "            \"message\": \"今日は何をしましたか？\"\n",
    "        }\n",
    "        '''\n",
    "    },\n",
    "    {\"role\": \"user\", \"content\": \"今日、僕は何が勉強しますか？\"},\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1beb9834-1706-46f8-a879-27aaf9677b99",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "「今日、僕は何を勉強しますか？」という質問は文法的に正しいです。ただし、もう少し自然な表現にするためには、「今日は何を勉強する予定ですか？」と言うと良いでしょう。\n",
      "\n",
      "それでは、何を勉強する予定ですか？どの科目に興味がありますか？\n"
     ]
    }
   ],
   "source": [
    "# gpt-3.5 fails to separate the feedback and the message?\n",
    "    # maybe I can have them as separate generations?\n",
    "    # but keep trying to modify the prompt.\n",
    "\n",
    "response = openai.ChatCompletion.create(\n",
    "    model = \"gpt-3.5-turbo\",\n",
    "    messages = conversation,\n",
    "    max_tokens = 500,\n",
    "    temperature = 0.0,\n",
    ")\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "719ea747-d941-49a4-8a9d-e2f633a6c142",
   "metadata": {},
   "source": [
    "Try to separate the response part and the feedback part into 2 calls\n",
    "<br> Use openAI for now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e68da07a-9435-4b44-9229-3fe83f45645d",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt_buddy = '''\n",
    "You are a practice buddy to a student learning Japanese.\n",
    "Converse with the student.\n",
    "The student is a native English speaker.\n",
    "If the student responds in another language, encourage him to chat in Japanese.\n",
    "You should only respond in Japanese.\n",
    "Use grammar and vocabulary appropriate for JLPT N4 level.\n",
    "Use both formal and casual Japanese so the student can learn both.\n",
    "If necessary, ask questions to keep the conversation going.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ae24936a-f2c2-4100-8151-395c12351468",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "こんにちは！日本語の練習、頑張りましょう！どんなことを練習したいですか？\n"
     ]
    }
   ],
   "source": [
    "query1 = \"こんにちは！今から日本語の練習します。\"\n",
    "\n",
    "conversation = [\n",
    "    {\n",
    "        \"role\": \"system\", \n",
    "        \"content\": system_prompt_buddy\n",
    "    },\n",
    "    {\"role\": \"user\", \"content\": query1},\n",
    "]\n",
    "\n",
    "response = openai.ChatCompletion.create(\n",
    "    model = \"gpt-3.5-turbo\",\n",
    "    messages = conversation,\n",
    "    max_tokens = 500,\n",
    "    temperature = 0.0,\n",
    ")\n",
    "print(response.choices[0].message.content)\n",
    "res_txt1 = response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f1b47400-c54f-4ca4-a18d-d49c9c03654a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "そうですか、土曜日はゆっくり寝ることができる日ですね。11時に起きたんですね。何時間寝たんですか？\n"
     ]
    }
   ],
   "source": [
    "query2 = \"今日は土曜日だよ。たくさんねました。11時に起きました。\"\n",
    "\n",
    "conversation = [\n",
    "    {\"role\": \"system\", \"content\": system_prompt_buddy},\n",
    "    {\"role\": \"user\", \"content\": query1},\n",
    "    {\"role\": \"assistant\", \"content\": res_txt1},\n",
    "    {\"role\": \"user\", \"content\": query2},\n",
    "]\n",
    "\n",
    "response = openai.ChatCompletion.create(\n",
    "    model = \"gpt-3.5-turbo\",\n",
    "    messages = conversation,\n",
    "    max_tokens = 500,\n",
    "    temperature = 0.0,\n",
    ")\n",
    "print(response.choices[0].message.content)\n",
    "res_txt2 = response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fa7d633c-9c72-438d-877a-193ece5e0744",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt_critic = '''\n",
    "You are an assistant to a student learning Japanese.\n",
    "A conversation will be provided between the student and the practice buddy.\n",
    "Instead of responding to the conversation, provide feedback on the grammar, vocabulary and overall language of the student.\n",
    "The student is a native English speaker.\n",
    "Provide feedback in English.\n",
    "Provide feedback that is appropriate for a JLPT N4 level.\n",
    "\n",
    "Focus on providing feedback on the latest response of the student.\n",
    "Avoid referring to previous responses unless necessary.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d01410cb-44f4-4283-97aa-8046912cd6c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STUDENT: こんにちは！今から日本語の練習します。\n",
      "PRACTICE BUDDY: こんにちは！日本語の練習、頑張りましょう！どんなことを練習したいですか？\n",
      "STUDENT: 今日は土曜日だよ。たくさんねました。11時に起きました。\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def conversation_to_txt(conversation, **kwargs):\n",
    "    '''\n",
    "    Convert a conversation to text which can be put into a single prompt.\n",
    "    NOTE: In Langchain, we will have to do this from the chat history / memory.\n",
    "    '''\n",
    "\n",
    "    conversation_str = \"\"\n",
    "\n",
    "    for response in conversation:\n",
    "        if response[\"role\"] == \"system\":\n",
    "            continue\n",
    "\n",
    "        elif response[\"role\"] == \"user\":\n",
    "            conversation_str += \"STUDENT: \" + response[\"content\"] + \"\\n\"\n",
    "\n",
    "        elif response[\"role\"] == \"assistant\":\n",
    "            conversation_str += \"PRACTICE BUDDY: \" + response[\"content\"] + \"\\n\"\n",
    "    \n",
    "    return conversation_str\n",
    "\n",
    "conversation_str = conversation_to_txt(conversation)\n",
    "print(conversation_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "51221ea1-83a0-4c5e-9c78-d8443c3ef2ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall, your response is good. Here are a few points to consider:\n",
      "\n",
      "1. In the sentence \"たくさんねました\", the verb \"ねました\" should be changed to \"ねました\" to match the past tense of the verb \"ねる\" (to sleep).\n",
      "\n",
      "2. Instead of saying \"今日は土曜日だよ\", it would be more natural to say \"今日は土曜日です\" to indicate that today is Saturday.\n",
      "\n",
      "3. In the sentence \"11時に起きました\", it would be more accurate to say \"11時に起きました\" to indicate that you woke up at 11 o'clock.\n",
      "\n",
      "Keep up the good work!\n"
     ]
    }
   ],
   "source": [
    "# gpt-3.5 gets the instruction right, but totally hallucinates.\n",
    "    # probably need to collect some references for n5 and n4\n",
    "    # then build a chain/tool/retriever to retrieve references\n",
    "        # but still okay to build this chain first then modify it later to retrieve references\n",
    "\n",
    "# gpt-4 actually gives more accurate feedback\n",
    "    # but probably don't want to rely on that coz it's expensive\n",
    "    # and also might get things wrong when we get to more complicated levels, grammar.\n",
    "\n",
    "query = '''\n",
    "Provide feedback for the student in the following conversation:\n",
    "{conversation_str}\n",
    "'''.format(conversation_str = conversation_str)\n",
    "\n",
    "conversation_critic = [\n",
    "    {\"role\": \"system\", \"content\": system_prompt_critic},\n",
    "    {\"role\": \"system\", \"content\": query},\n",
    "]\n",
    "\n",
    "response = openai.ChatCompletion.create(\n",
    "    model = \"gpt-3.5-turbo\",\n",
    "    messages = conversation_critic,\n",
    "    max_tokens = 500,\n",
    "    temperature = 0.0,\n",
    ")\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd21f8f3-0b3b-48c5-ac32-db88d1a297dd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "052ebaee-04fa-404a-aff0-3d8e06055008",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
